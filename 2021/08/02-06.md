> 2021 08.02 - 06 

**REF 컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커**

쿠버네티스 기초 이해를 위해 마스터 노드를 클라우드 업체에서 관리하는 관리형 쿠버네티스를 사용하지 않고 온프레미스를 지원하는 구성형 쿠버네티스 중 kubeadm 을 이용했다. 

온프레미스 환경 구축을 위해 virtualbox 와 vagrant 를 이용하여 가상머신을 생성하고 환경을 설정했다. 

가상 머신은 총 4개를 생성하여 쿠버네티스 클러스터를 구성하는 한개의 마스터 노드와 3개의 워커 노드로 구성했다.

## 마스터 노드에는 
* 쿠버네티스 클러스터와 통신하는 **kubectl**
* 모든 요소와 통신하며 클러스터의 상태를 관리하는 **API 서버**
* 클러스터의 구성 요소들의 상태 값이 모두 저장되는 **etcd** 
* 클러스터의 오브젝트 상태를 관리하는 **컨트롤러 매니저**
* 노드의 상태와 자원, 조건을 고려해 파드를 어떤 워커 노드에 생성할 것인지 결정하고 할당하는 **스케줄러**

## 워커 노드에는
* 파드의 구성 내용을 받아서 컨테이너 런타임으로 전달하고, 파드 안의 컨테이너들이 정상적으로 작동하는지 모니터링 하는 **kubelet**
* 파드 안에서 다양한 컨테이너가 문제 없이 작동하게 만드는 표준 인터페이스인 **컨테이너 런타임**

## 그 외
* 쿠버네티스 클러스터의 통신을 위해 **네트워크 플러그인**을 구성하는데 일반적으로 CNI 로 구성하며 그 중 L3 네트워크를 구성하는 캘리코를 선택해서 구성했다. 
* 파드의 생성과 상태 관리 및 복구 등을 담당하는게 kubelet 이라면 파드의 통신을 담당하는 **kube-proxy**가 있다. 
  
---

\
**kubelet** 은 쿠버네티스에서 파드의 생성과 상태 관리 및 복구를 담당하는 요소라고 했는데 이를 확인 하기 위해 워커 노드에 kubelet을 종료하고 파드가 관리되는지 확인했다.

```python
# 파드를 생성한다.
kubectl create deployment nginx-pod --image=nginx

# 파드가 생성된 워커 노드에서 kubelet 서비스를 중단한다.
systemctl stop kubelet

# 파드를 삭제한다
kubelet delete deployment nginx-pod

```
파드의 상태를 확인해보면 Terminating(삭제 중) 이라는 문구만 뜨고 실제로 삭제되지 않고 있습니다. 

```python
# 워커 노드에 다시 kubelet을 복구한다.

systemctl start kubelet

# 파드의 상태를 확인해보면 정상적으로 삭제된 것을 알 수 있다. 
```
kube-proxy 는 파드의 통신을 담당한다. 클러스터를 구축할 때 br_netfilter 커널 모듈을 적재하고 iptables 를 거쳐 통신하도록 설정했는데 br_netfilter 모듈을 제거하면 파드가 통신 할 수 있는지 살펴봤다.

```python
# 파드를 생성한다.
kubectl create deployment nginx-pod --image=nginx

# 파드의 IP 를 확인한다.
kubectl get pod -o wide

# client URL 로 파드의 ip 로 nginx 웹 서버 메인 페이지 내용을 확인한다.
curl 172.16.132.25

# 파드가 생성된 워커 노드에서 문제 상황을 위해 br_netfilter 모듈을 제거한다.
modprobe -r br_netfilter

# 워커 노드 네트워크를 다시 시작하여 변경사항을 저장한다.
systemctl restart network

# 파드에 접속해본다.
curl 172.16.132.25

```

아무런 응답을 받지 못하는 것을 확인했다. 


--- 
\
쿠버네티스에서 파드와 디플로이먼트는 **Spec , Status** 의 값을 가지는데 이러한 파드와 디플로이먼트를 **개별 속성**을 포함해 부르는 단위를 **오브젝트**라고 한다. 

기본 오브젝트 중 

**네임스페이스** 는 쿠버네티스 클러스터에서 사용되는 리소스들을 구분해 관리하는 그룹이다. 내가 실습한 환경은 기본으로 할당되는 default, 쿠베네티스 시스템에서 사용되는 kube-system, 온프레미스 환경에서 외부에서 클러스터 내부의 접속을 도와주는 컨테이너가 속해 있는 metallb-system 이 있다.

**서비스** 파드의 접속을 안정적으로 유지하도록 서비스를 통해 내/외부로 연결된다. 왜냐하면 쿠버네티스에서 파드는 언제든 지워질 수 있고 대체되는 개념이기 때문에 접속 정보가 고정일 수 없기 때문이다. 그래서 서비스는 새로운 파드의 새로운 IP를 기존에 제공하던 기능과 연결해 준다. 

___
\
쿠버네티스는 파드에 문제가 발생하면 파드를 자동 복구해서 항상 동작하도록 보장하는 기능이 있다. 이 것을 확인해봤다. 

```python
# 단일 파드를 생성한다. 
kubectl run nginx-pod --image=nginx

# 디플로이먼트에 속한 파드를 생성한다. 
kubectl create deployment dpy-nginx-pod --image=nginx

# replicas 를 6으로 늘려준다
kubectl scale deployment dpy-nginx-pod --replicas=6

```

파드를 확인하면 총 7개의 파드가 실행되고 있는 것을 확인 할 수 있다.

```python
# 단일 파드와 디플로이먼트에 속한 파드 하나를 삭제해보자.
kubectl delete pod nginx-pod

kubectl delete pod dpy-nginx-pod-66c4c6f49f-2fjsq

```

다시 파드를 확인해보면 단일 파드는 삭제되고 디플로이먼트에 속한 파드는 삭제 되었지만 replicas 로 설정된 개수를 맞추기 위해 새로운 파드를 1개 생성한 것을 AGE 와 Name 으로 확인 할 수 있다. 

이유는 단일 파드는 관리하는 컨트롤러가 없지만 디플로이먼트는 래플리카셋 컨트롤러에서 관리하기 때문이다. 

---
\
파드 rollout / rollback 기능 

파드를 운영하다 보면 컨테이너에 새로운 기능을 추가하거나 버전을 업데이트 해야하는 경우가 있다. 또한 문제가 업데이트 중 문제가 발생하면 기존 버전으로 복구해야하는 일이 필요하다. 

```python
# nginx:1.15.12 버전으로 파드를 생성한고 replicas 3개로 늘린다.
kubectl create deployment dpy-nginx --image=nginx:1.15.12
kubectl scale deployment dpy-nginx --replicas=3

# 헤더의 정보를 확인하는 curl -I 로 nginx 컨테이너 버전을 확인한다.
curl -I --silent 172.16.221.150 | grep Server

# nginx: 1.16.0 버전으로 업데이트 후 record 한다.
kubectl set image deployment dpy-nginx nginx=nginx:1.16.0 --record

```

파드 정보를 확인하면 이름과 IP가 다른 것을 보아 기존 파드가 삭제되고 새로운 레플리카셋이 생성된 것을 확인 가능하다.

이는 파드를 업데이트하는 방법 중 가장 편한 방법이 기존의 레플리카셋을 삭제 시키고 새로운 버전을 가진 레플리카셋을 생성하는 것이 가장 쉽다. 이때 시스템에 영향을 최소화하기 위해 한번에 지우고 생성하는 것이 아닌 순차적으로 진행한다. 

rollback 방법은

```python
# nginx 없는 버전인 1.17.23 으로 업데이트를 실시한다.
kubectl set image deployment dpy-nginx nginx=nginx:1.17.23 --record

# 파드 상태를 확인하면 이미지를 받는데 실패했다는 상태가 나온다. 

# 디플로이먼트의 히스토리를 확인하자
kubectl rollout history deployment dpy-nginx 

# 히스토리에 특정시점으로 rollback 시키자.
kubectl rollout undo deployment dpy-nginx --to-revision=2

# nginx 컨테이너의 버전을 확인한다.
curl -I --silent 172.16.180.9 | grep Server
```

---
\

쿠버테니스에서 파드는 쉽게 삭제되고 복구되는 개념이기 때문에 고정된 엔드포인트로 호출이 어렵다. 또한 여러 파드에 같은 어플리케이션을 운영할 경우 파드들 간의 로드밸런싱을 지원해 주어야하는데 서비스가 이러한 역할을 한다. 

서비스는 지정된 IP 로 생성 가능하고 여러 파드를 묶어서 로드밸런싱이 가능하며 고유한 DNS 이름을 가질 수 있다.

온프레미스 환경에서 로드밸런서라는 서비스 타입을 사용하기 위해 MetalLB 로 구현해봤다.

```python
# 디플로이먼트를 로드밸런서 서비스로 노출한다.
kubectl expose deployment dpy-nginx --type=LoadBalancer --name=nginx-svc --prot=80

# 서비스의 EXTERNAL-IP 를 확인하고 해당 ip로 접속해본다.
kubectl get service

```

인터넷에 서비스 IP 로 접근하면 nginx 의 메인 홈페이지를 확인할 수 있다.

---
\
외부에서 엄청 많은 사용자가 어플리케이션에 접근한다면 파드가 하나라면 엄청난 부하량 때문에 감당하지 못할 수 있다. 이런 경우를 대비해 쿠버네티스는 유동적으로 파드 수를 관리하는 기능을 제공한다. 이를 HPA 라고 한다. 

부하량에 따라 파드를 늘려주고 부하량이 줄어들면 파드를 줄여주는 기능이다. 

